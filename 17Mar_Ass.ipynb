{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ed45b1-5337-4312-9c0a-8832d6c5d620",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some  algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e1e48-91ef-461d-ba75-cd9843641810",
   "metadata": {},
   "source": [
    "Missing data, or missing values, occur when you don't have data stored for certain variables or participants. Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons. In any dataset, there are usually some missing data.\n",
    "\n",
    "The first approach is to replace the missing value with one of the following strategies:\n",
    "\n",
    "Replace it with a constant value. ...\n",
    "\n",
    "Replace it with the mean or median. ...\n",
    "\n",
    "Replace it with values by using information from other columns.\n",
    "\n",
    "k-NN and Random Forest algorithms can also support missing values. the k-NN algorithm considers the missing values by taking the majority of the K nearest values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcced12-0abe-4af1-bd64-9eb47e9cc032",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4cc5e6-9494-4585-924b-e74cab88eb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n1  n2\n",
       "0   4   3\n",
       "1   5   4\n",
       "2   6   6\n",
       "3   0   8\n",
       "4   8   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic technique to handle missing data\n",
    "#mean\n",
    "#median \n",
    "#mode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'n1':[4,5,6,0,8],\n",
    "       'n2':[3,4,6,8,0]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c712f1c-855e-4689-94bb-74bffb9cc4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets assume 0 as a missing value\n",
    "df.n1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc3e038-0d65-4521-b0be-59049beeec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n1  n2\n",
       "0  4.0   3\n",
       "1  5.0   4\n",
       "2  6.0   6\n",
       "3  4.6   8\n",
       "4  8.0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n1.replace(0,4.6,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578db831-e604-416b-b793-7dfb4fa4210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n2.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3f3941-7d4e-434d-879e-3af2d281c326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n1  n2\n",
       "0  4.0   3\n",
       "1  5.0   4\n",
       "2  6.0   6\n",
       "3  4.6   8\n",
       "4  8.0   4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n2.replace(0,4.0,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0410c-f615-480f-8ef5-24602ea0ea42",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcf41c-9db5-45f2-95b4-d5d505a91391",
   "metadata": {},
   "source": [
    "Imbalanced datasets mean that the number of observations differs for the classes in a classification dataset. This imbalance can lead to inaccurate results. In this article we will explore techniques used to handle imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6c97e-7b0f-4938-8856-ce3d5ea69a6f",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27273e2d-71cd-4a04-97e7-ee1042f994ee",
   "metadata": {},
   "source": [
    "Downsampling (in this context) means training on a disproportionately low subset of the majority class examples. Upweighting means adding an example weight to the downsampled class equal to the factor by which you downsampled.\n",
    "\n",
    "EXAMPLE:\n",
    "If there are two features in a dataset and total number of data is 1000. first feature has 800 datapoints and second feature has 200 datapoints than we can use up-sampling to increase the number of second feature.\n",
    "We can use the down-sampling for vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9220a3-2b40-4f8e-9d6e-ac1753b8c369",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b1ecb-d019-4ec6-abe4-16a2b2b52518",
   "metadata": {},
   "source": [
    "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.\n",
    "\n",
    "\n",
    "SMOTE is an over-sampling technique focused on generating synthetic tabular data. The general idea of SMOTE is the generation of synthetic data between each sample of the minority class and its “k” nearest neighbors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d73348-9b09-48f3-825e-ec5fbb55e390",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34be5e2-c2c3-4bdf-a458-f8b879dd2c3c",
   "metadata": {},
   "source": [
    " An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. In a sense, this definition leaves it up to the analyst (or a consensus process) to decide what will be considered abnormal.\n",
    " \n",
    " Outliers are important because they can have a large influence on statistics derived from the dataset. For example, the mean intake of energy or some nutrient may be [glossary term:] skewed upward or downward by one or a few extreme values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de744dd5-1bf8-4bb9-b5de-a0738e13a89e",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ebef3-099a-447a-a687-59c14ecd7f13",
   "metadata": {},
   "source": [
    "Mean:\n",
    "\n",
    "If the data is normally distributed and numeric than we can use mean to fill the missing data.\n",
    "\n",
    "Median:\n",
    "\n",
    "If the data has outliers and it is numeric then,we can use median to fill the missing data.\n",
    "\n",
    "\n",
    "Mode:\n",
    "\n",
    "If the data is categorical then we should use mode.\n",
    "\n",
    "\n",
    "Other options are, we can drop the columns or a row completely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299cd91-d634-4da6-bec5-534c78dbf2af",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01425ad6-fc04-4f71-9bac-55397e88c6ec",
   "metadata": {},
   "source": [
    "Check the percentage of missing data: If the percentage of missing data is small (less than 5%), it is more likely that the missing data is missing at random. However, if the percentage of missing data is high (more than 10%), it is more likely that there is a pattern to the missing data.\n",
    "\n",
    "\n",
    "Look for patterns in the missing data: Are the missing data clustered in certain rows or columns? Are they missing for certain values of a variable? If you see any patterns, it suggests that the missing data is not missing at random.\n",
    "\n",
    "\n",
    "Use statistical tests: There are a number of statistical tests that can be used to determine if the missing data is missing at random. These tests can be more accurate than simply looking for patterns, but they can also be more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada48328-1e06-4922-8d85-a724c522477e",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31357d9d-5a8e-4f61-a746-287295c1e2cb",
   "metadata": {},
   "source": [
    "Use metrics that are specifically designed for imbalanced datasets. Some examples of these metrics include precision, recall, and the F1 score. Precision measures the percentage of predictions that were positive and were actually positive. Recall measures the percentage of positive examples that were correctly predicted as positive. The F1 score is a weighted average of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b4b8b-55b4-4c72-bcc7-09303ff13be5",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5c981-b0d7-4310-b048-99c22654b7f1",
   "metadata": {},
   "source": [
    "Random undersampling: This involves randomly removing data points from the majority class until the dataset is balanced. This is the simplest method, but it can also be the most harmful to the model's performance. If you remove too many data points, you may not have enough data to train the model effectively.\n",
    "\n",
    "\n",
    "Stratified undersampling: This involves randomly removing data points from the majority class in a way that preserves the distribution of the minority class. This can be a more effective method than random undersampling, but it can also be more computationally expensive.\n",
    "\n",
    "\n",
    "Synthetic minority oversampling technique (SMOTE): This involves creating synthetic data points for the minority class by interpolating between existing data points. This can be a more effective method than undersampling, but it can also be more computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec5c0f-6cea-4699-83e1-17d3c9eeaf2a",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b544c-c5ec-4bd9-acff-044e4bccd6f5",
   "metadata": {},
   "source": [
    "Random undersampling: This involves randomly removing data points from the majority class until the dataset is balanced. This is the simplest method, but it can also be the most harmful to the model's performance. If you remove too many data points, you may not have enough data to train the model effectively.\n",
    "\n",
    "\n",
    "Stratified undersampling: This involves randomly removing data points from the majority class in a way that preserves the distribution of the minority class. This can be a more effective method than random undersampling, but it can also be more computationally expensive.\n",
    "\n",
    "\n",
    "Synthetic minority oversampling technique (SMOTE): This involves creating synthetic data points for the minority class by interpolating between existing data points. This can be a more effective method than undersampling, but it can also be more computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72c668-3cff-4713-81be-bd0dd6c78ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
