{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6fd20d-e6bf-4d76-af4f-51d74c2772ef",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56fb61-9441-4ab7-b4af-4a1247a20780",
   "metadata": {},
   "source": [
    "Bayes' theorem is a formula in probability theory that describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is named after Thomas Bayes, a British mathematician who first published it in 1763.\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A)P(A) / P(B)\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) is the posterior probability of event A occurring after the completion of event B\n",
    "\n",
    "P(B|A) is the likelihood of event B occurring given event A\n",
    "\n",
    "P(A) is the prior probability of event A\n",
    "\n",
    "P(B) is the marginal probability of event B\n",
    "\n",
    "The posterior probability is the probability of event A occurring given that we know event B has occurred. The likelihood is the probability of event B occurring given that we know event A has occurred. The prior probability is the probability of event A occurring before we know anything about event B. The marginal probability is the probability of event B occurring without regard to event A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d6cff-82fb-4ae2-b5bb-8023809c6d2f",
   "metadata": {},
   "source": [
    "## Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93e081-09d9-483a-914a-6053e92410aa",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A)P(A) / P(B)\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) is the posterior probability of event A occurring after the completion of event B\n",
    "\n",
    "P(B|A) is the likelihood of event B occurring given event A\n",
    "\n",
    "P(A) is the prior probability of event A\n",
    "\n",
    "P(B) is the marginal probability of event B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ffad6-ecdf-4c4d-b17e-7b942a3a7e3a",
   "metadata": {},
   "source": [
    "## Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1433223-2921-4f6d-af80-8e778be9008b",
   "metadata": {},
   "source": [
    "\n",
    "Bayes' theorem is used in practice in many different ways. Here are some examples:\n",
    "\n",
    "Medical diagnosis: Bayes' theorem can be used to diagnose diseases by updating our beliefs about the probability of a disease based on the patient's symptoms and test results. For example, if a patient has a fever and a positive test result for influenza, Bayes' theorem can be used to calculate the probability that the patient actually has influenza.\n",
    "\n",
    "Fraud detection: Bayes' theorem can be used to detect fraud by updating our beliefs about the probability of fraud based on the customer's spending habits and other information. For example, if a customer suddenly starts spending a lot of money on online purchases, Bayes' theorem can be used to calculate the probability that the customer is committing fraud.\n",
    "\n",
    "Risk assessment: Bayes' theorem can be used to assess the risk of events such as natural disasters, financial crises, and terrorist attacks. For example, if a country has a history of earthquakes, Bayes' theorem can be used to calculate the probability of an earthquake occurring in that country.\n",
    "\n",
    "Machine learning: Bayes' theorem is used in many machine learning algorithms, such as Naive Bayes classifiers and Bayesian networks. These algorithms can be used to classify data, make predictions, and solve other problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869495b-4cd1-452d-86c1-f18ce92571d7",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d327f52-a219-431b-b8a2-0eec93519cb7",
   "metadata": {},
   "source": [
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. Bayes' theorem can be used to calculate the conditional probability of an event, given that we know another event has occurred.\n",
    "\n",
    "The conditional probability of event A given event B is the probability of event A occurring, given that we know event B has already occurred. It is calculated as follows:\n",
    "\n",
    "P(A|B) = P(A and B) / P(B)\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) is the conditional probability of event A given event B\n",
    "\n",
    "P(A and B) is the probability of events A and B occurring together\n",
    "\n",
    "P(B) is the probability of event B occurring\n",
    "\n",
    "Bayes' theorem can be used to calculate the conditional probability of event A given event B as follows:\n",
    "\n",
    "P(A|B) = P(B|A)P(A) / P(B)\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) is the conditional probability of event A given event B\n",
    "\n",
    "P(B|A) is the likelihood of event B occurring given event A\n",
    "\n",
    "P(A) is the prior probability of event A\n",
    "\n",
    "P(B) is the marginal probability of event B\n",
    "\n",
    "The likelihood of event B occurring given event A is the probability of event B occurring, given that we know event A has already occurred. The prior probability of event A is the probability of event A occurring before we know anything about event B. The marginal probability of event B is the probability of event B occurring without regard to event A.\n",
    "\n",
    "In other words, Bayes' theorem can be used to update our beliefs about the probability of event A occurring, given that we know event B has occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91baf8-5e5d-4515-8f7d-efcf778f8410",
   "metadata": {},
   "source": [
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2c122-8e54-4db1-8878-6d5442c5c60f",
   "metadata": {},
   "source": [
    "There are three main types of Naive Bayes classifiers:\n",
    "\n",
    "Multinomial Naive Bayes: This classifier is used for classification problems where the features are discrete and can be represented as counts. For example, the features could be the number of times a particular word appears in a document.\n",
    "\n",
    "Bernoulli Naive Bayes: This classifier is used for classification problems where the features are binary, i.e., they can take on only two values, such as true or false. For example, the features could be whether a particular email is spam or not spam.\n",
    "\n",
    "Gaussian Naive Bayes: This classifier is used for classification problems where the features are continuous, i.e., they can take on any value within a range. For example, the features could be the height or weight of a person.\n",
    "\n",
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the features. If the features are discrete and can be represented as counts, then the Multinomial Naive Bayes classifier is a good choice. If the features are binary, then the Bernoulli Naive Bayes classifier is a good choice. If the features are continuous, then the Gaussian Naive Bayes classifier is a good choice.\n",
    "\n",
    "In addition to the type of features, the choice of Naive Bayes classifier also depends on the size of the dataset. If the dataset is small, then the Multinomial Naive Bayes classifier is a good choice because it is less computationally expensive than the other two types of classifiers. If the dataset is large, then the Bernoulli Naive Bayes classifier or the Gaussian Naive Bayes classifier may be a better choice because they can be more accurate.\n",
    "\n",
    "Finally, the choice of Naive Bayes classifier also depends on the desired accuracy. If high accuracy is required, then the Gaussian Naive Bayes classifier may be a better choice than the other two types of classifiers. However, the Gaussian Naive Bayes classifier is also more computationally expensive than the other two types of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803900b-97f6-4852-b04e-caa1e7714229",
   "metadata": {},
   "source": [
    "## Q6. Assignment:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4079270-a6cc-40a6-b80d-808a3f7615c0",
   "metadata": {},
   "source": [
    "\n",
    "### You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use NaiveBayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class: Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4 A 3 3 4 4 3 3 3 B 2 2 1 2 2 2 3 Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79148fe-4201-496a-b4fd-a6a2a51598ae",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier works by assuming that the features are independent of each other. In this case, the features are X1 and X2. The table shows the frequency of each feature value for each class.\n",
    "\n",
    "To classify the new instance with features X1 = 3 and X2 = 4, we need to calculate the posterior probability of each class. The posterior probability is the probability of a class given the features. It can be calculated using Bayes' theorem:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3,X2=4|A)P(A) / P(X1=3,X2=4)\n",
    "\n",
    "where\n",
    "\n",
    "P(A|X1=3,X2=4) is the posterior probability of class A given the features X1 = 3 and X2 = 4\n",
    "\n",
    "P(X1=3,X2=4|A) is the likelihood of the features X1 = 3 and X2 = 4 given class A\n",
    "\n",
    "P(A) is the prior probability of class A\n",
    "\n",
    "P(X1=3,X2=4) is the marginal probability of the features X1 = 3 and X2 = 4\n",
    "\n",
    "The prior probability of each class is equal, so P(A) = P(B) = 0.5.\n",
    "\n",
    "The likelihood of the features X1 = 3 and X2 = 4 given class A can be calculated as follows:\n",
    "\n",
    "P(X1=3,X2=4|A) = (4/10)*(3/10) = 12/100\n",
    "\n",
    "The marginal probability of the features X1 = 3 and X2 = 4 can be calculated as follows:\n",
    "\n",
    "P(X1=3,X2=4) = (4/10)*(3/10) + (2/10)*(3/10) = 18/100\n",
    "\n",
    "Therefore, the posterior probability of class A given the features X1 = 3 and X2 = 4 is:\n",
    "\n",
    "P(A|X1=3,X2=4) = (12/100)*(0.5) / (18/100) = 2/3\n",
    "\n",
    "The posterior probability of class B given the features X1 = 3 and X2 = 4 is:\n",
    "\n",
    "P(B|X1=3,X2=4) = (6/100)*(0.5) / (18/100) = 1/3\n",
    "\n",
    "Since the posterior probability of class A is higher than the posterior probability of class B, the Naive Bayes classifier would predict the new instance to belong to class A.\n",
    "\n",
    "Here is a summary of the steps involved in the Naive Bayes classification:\n",
    "\n",
    "Calculate the prior probabilities of each class.\n",
    "\n",
    "Calculate the likelihood of the features given each class.\n",
    "\n",
    "Calculate the posterior probabilities of each class.\n",
    "\n",
    "Choose the class with the highest posterior probability.\n",
    "\n",
    "In this case, the prior probabilities of each class are equal. The likelihood of the features X1 = 3 and X2 = 4 given class A is 12/100. The likelihood of the features X1 = 3 and X2 = 4 given class B is 6/100. The posterior probability of class A is 2/3. The posterior probability of class B is 1/3. Therefore, the Naive Bayes classifier would predict the new instance to belong to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3cabd-27bc-4d7a-8cfe-cc301888a4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
